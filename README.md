## ğŸ§  Conversational MongoDB Agent
---
This project allows natural language querying of a financial MongoDB database using a local LLM (e.g., Mistral-7B Instruct) and provides both:

* ğŸ–¥ï¸ A REST API via **FastAPI**
* ğŸ’¬ A chat-based UI via **Streamlit**

> Users can ask questions like:
> *"Show me all transactions over \$1000 in the last 7 days"*
> and get structured MongoDB queries, results, and a human-friendly summary.

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ .env
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ ui.py               # Streamlit UI app
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ langchain_agent.py
â”‚   â”‚   â”œâ”€â”€ query_builder.py
â”‚   â”‚   â”œâ”€â”€ summarizer.py
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ query_executor.py
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ config.py       # Loads Mongo URI and secrets
â”œâ”€â”€ models/
â”‚   â””â”€â”€ mistral-7b-instruct-v0.2/  # Downloaded HuggingFace model folder
â””â”€â”€ main.py                 # FastAPI backend entry
```

---

Hereâ€™s a clear and professional attribution statement for the **Kaggle financial dataset** you used earlier, which you can include in your `README.md`, documentation, or app footer:

---

## ğŸ“Š Dataset Attribution

This project utilizes a financial dataset originally sourced from [Kaggle](https://www.kaggle.com/) for demonstration and experimentation purposes.

**Dataset Title:** Huge Stock Market Dataset
**Source:** Kaggle Dataset URL - https://www.kaggle.com/datasets/borismarjanovic/price-volume-data-for-all-us-stocks-etfs/data

The dataset contains anonymized financial records including **stocks, ETFs**, and has been preprocessed to suit MongoDB storage and natural language querying tasks.

### ğŸ“¦ MongoDB Sample Dataset

This project also uses the **`sample_analytics`** dataset provided by [MongoDB Atlas Sample Datasets](https://www.mongodb.com/docs/atlas/sample-data/).
It includes anonymized financial and customer analytics data, ideal for demonstrating aggregation pipelines and query generation tasks.

> âœ… All data is used under the terms of the Kaggle dataset's open license. Please refer to the [dataset page](https://www.kaggle.com/) for licensing and citation requirements.

---
## âš™ï¸ .env Setup
```ini
MONGO_USER=your_mongodb_user
MONGO_PASS=your_mongodb_password
DATABASE_NAME=sylvr_finance
```

---

## ğŸ§ª Sample Prompts (Try these in UI)

| Natural Query                                           | Target Collection       |
| ------------------------------------------------------- | ----------------------- |
| Show me all transactions over \$1000 in the last 7 days | `transactions`          |
| List customers who opened accounts this year            | `customers`, `accounts` |
| What ETFs have gained over 5% this month?               | `ETFs`                  |
| Get accounts with balances above \$50,000               | `accounts`              |
| Which stocks were traded most in last 24h?              | `stocks`                |

---

## ğŸ§  Code Flow Overview

1. **Query is entered** (via Streamlit or `/query` API).
2. `query_builder.py`:

   * Converts natural language â†’ MongoDB JSON query using local LLM.
3. `query_executor.py`:

   * Executes Mongo query on selected collection.
4. `summarizer.py`:

   * Summarizes the output using local LLM.
5. `langchain_agent.py`:

   * Coordinates single-shot and multi-turn chat workflows.
6. `ui.py`:

   * Renders full frontend chat interface using Streamlit.
7. `main.py`:

   * Runs FastAPI backend for programmatic access.

---

## ğŸ”Œ Run Locally Without Docker

### 1. Clone Repo & Install

```bash
git clone [https://github.com/yourname/mongo-conversational-agent.git](https://github.com/RamakrishnaReddyPalle/conversationsal-db-agent.git)
cd conversational-db-agent
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### 2. Download the Model (One-Time)

```bash
from transformers import AutoModelForCausalLM, AutoTokenizer
AutoModelForCausalLM.from_pretrained("mistralai/Mistral-7B-Instruct-v0.2", cache_dir="models/mistral-7b-instruct-v0.2")
AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.2", cache_dir="models/mistral-7b-instruct-v0.2")
```

OR download manually from [ğŸ¤— Hugging Face](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) into `./models/mistral-7b-instruct-v0.2/`.

### 3. Start FastAPI Backend

```bash
uvicorn main:app --reload
```

You can now test via **Swagger UI**:

```
http://localhost:8000/docs
```

---

### 4. Start Streamlit Frontend

```bash
streamlit run frontend/ui.py
```

Visit:

```
http://localhost:8501
```

---

## ğŸ³ Docker Deployment

### 1. Build Docker Image

```bash
docker build -t mongo-agent .
```

### 2. Run Docker Container

```bash
docker run -d -p 8000:8000 --env-file .env mongo-agent
```

> Note: Streamlit must be run **outside** or in a separate container.

---

## ğŸŒ Swagger Test Guide

1. Go to: [http://localhost:8000/docs](http://localhost:8000/docs)
2. Use the `/query` endpoint with query param:

   ```
   natural_query = Show me all transactions over $1000 in the last 7 days
   ```
3. Check returned MongoDB query, results, and summary.
